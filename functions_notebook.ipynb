{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#DF1525'>  \n",
    "\n",
    "## Disclaimer:  \n",
    "  \n",
    "A ideia de criar um notebook organizacional foi herdada do P3 feito por Giovanni Rozatti (em conjunto com Daniel G. Terra e Rafael B. Zanfolin) no semestre anterior, o repositório para esse notebook daquele projeto se encontra no link a seguir:`https://github.com/VonIgnia/C.Dados-P3/blob/master/Classificador2/_Fun%C3%A7%C3%B5es.ipynb`\n",
    "- A ideia original pertence a Daniel Terra, e sua execução(no Projeto 3) foi feita em conjunto com Giovanni Rozatti\n",
    "- A maior parte das funções nesse notebook é inédita, apesar de bastante simlares àquele, isso ocorre pois as mesmas fontes (vistas em [Links e Referências](Links%20e%20Refer%C3%AAncias.md)) foram consultadas\n",
    "- Partes diretmente extraídas daquele serão antecedidas por outro disclaimer  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos do Notebook:\n",
    "- O principal propósito desse notebook é a hospedagem e organização das funções que serão utilizados nos outros notebooks desse projeto.  \n",
    "- Outro propósito é uma breve explicação do funcionamento individual de cada uma delas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Imports iniciais\n",
    "- Importa bibliotecas e funções com que trabalharemos ao longo desse notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biblioteecas para manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas para deixar determinados trechos \"user friendly\" e interativos\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca para criação de gráficos e visualizações de dados\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca de Machine Learning Open source para python\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Dados\n",
    "- Importa nossa base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados=pd.read_csv('cars_Brazil_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optamos por trabalhar apenas com carros que apareçam no Dataset no mínimo 500 vezes, esse valor foi escolhido de forma a separar o Dataset individual de cada carro em teste e treinamento, com 10% (no mínimo 50 linhas) do Dataset sendo direcionado para teste.   \n",
    "    - <font color=\"#F02510\"> **Observação 04/06: Talvez seja viável reduzir esse limite para 300, em contraponto o limite de 500 já fornece uma base de dados extensa o bastante e informações que parecem ser suficientes para elaborar uma conclusão.** </font>\n",
    "    - Colunas de caracerísticas qualitativas nominais devem ser transformadas em variáveis Dummy e/ou Hot End, caso contrário a predição não pode ser feita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separa carros com mais de 500 ocorrências no Dataframe\n",
    "Mais_de_500 = Dados['nome'].value_counts() > 500\n",
    "Mais_de_500 = list(Mais_de_500.loc[Mais_de_500].index)\n",
    "Dados = Dados.loc[Dados['nome'].isin(Mais_de_500),:];\n",
    "\n",
    "#Converte as variáveis quali em quanti através do uso de Dummy Variables:\n",
    "Dummies = pd.get_dummies(Dados.drop(columns=['nome']), prefix=['marca', 'categoria','loc']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando 10% do Dataframe global para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separa características dos carros, que podem ser relevantes no contexto de uma regrssão e \\n\n",
    "# elimina as características irrelevantes assim como a coluna com resultado esperado;\n",
    "inputs = Dummies.drop(columns=[\"valor\"])\n",
    "\n",
    "#separa o resultado esperado, devemos calcular a previsão mais próxima a eles;\n",
    "target = Dummies[\"valor\"]\n",
    "\n",
    "#separando dataframes teste e treino\n",
    "X_train,X_test,Y_train,Y_test=tts(inputs,target,test_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando 10% do Dataframe de cada carro para treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando dicionários, pois eles são melhores para chamar um grande número de valores armazenados\n",
    "Carro         = {}\n",
    "Carro_inputs  = {}\n",
    "Carro_target  = {}\n",
    "Carro_X_train = {}\n",
    "Carro_X_test  = {}\n",
    "Carro_Y_train = {}\n",
    "Carro_Y_test  = {}\n",
    "Carro_Y_predict = {}\n",
    "\n",
    "for x in Mais_de_500:\n",
    "    Carro[x] = Dummies.loc[Dados['nome'] == x]\n",
    "        \n",
    "    Carro_inputs[x] = Carro[x].drop(columns=[\"valor\"])\n",
    "    Carro_target[x] = Carro[x][\"valor\"]\n",
    "        \n",
    "    #separando dataframes teste e treino\n",
    "    Carro_X_train[x],Carro_X_test[x],Carro_Y_train[x],Carro_Y_test[x]=tts(Carro_inputs[x],Carro_target[x],test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar essa informação com a função interact do ipywidgets\n",
    "def Separa_dataframe_por_carro(x):\n",
    "    return (Carro_X_train[x],Carro_X_test[x],Carro_Y_train[x],Carro_Y_test[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Pré Processamento de Modelos de Regressão e Classificação do SKLearn:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression (da Biblioteca SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Regression_individual(x):\n",
    "    ### Declarando o modelo como variável global, para que ele possa ser chamado novamente sem perda ou alteração de valor\n",
    "    global model_1\n",
    "    \n",
    "    ### Escolhendo o modelo na biblioteca SciKitLearn\n",
    "    model_1 = LinearRegression()\n",
    "    \n",
    "    ### Fazendo o ajuste do modelo\n",
    "    model_1.fit(Separa_dataframe_por_carro(x)[0],Separa_dataframe_por_carro(x)[2])\n",
    "    \n",
    "    ### Usando o modelo ajustado para elaborar uma predição\n",
    "    Carro_Y_predict = {}\n",
    "    Carro_Y_predict[x] = model_1.predict(Carro_X_test[x])\n",
    "    \n",
    "    ### Calculando as métricas que determinam a qualidade do modelo\n",
    "    r_2 = model_1.score(Separa_dataframe_por_carro(x)[1],Separa_dataframe_por_carro(x)[3])\n",
    "    MSE  = mean_squared_error (Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    MAE  = mean_absolute_error(Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    \n",
    "    #Função de plotagem com seaborn extraída de:`https://onestopdataanalysis.com/scatter-plot-python/`\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Separa_dataframe_por_carro(x)[3],Carro_Y_predict[x], color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "    \n",
    "    ### Imprimindo as métricas\n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Regression Tree (da Biblioteca SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avisos:\n",
    "    - Apesar do valor default do `random_state` ser `None`, ainda haviam varaiações de resultados quando o modelo era rodado(sem alterar a base de treinamento), isso foi solucionado ao trocar o valor  do `random_state` por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_Tree_individual(x):\n",
    "    ### Declarando o modelo como variável global, para que ele possa ser chamado novamente sem perda ou alteração de valor\n",
    "    global model_2\n",
    "    \n",
    "    ### Escolhendo o modelo na biblioteca SciKitLearn\n",
    "    model_2 = DecisionTreeRegressor(max_depth=12,random_state=0)\n",
    "    \n",
    "    ### Fazendo o ajuste do modelo\n",
    "    model_2.fit(Separa_dataframe_por_carro(x)[0],Separa_dataframe_por_carro(x)[2])\n",
    "    \n",
    "    ### Usando o modelo ajustado para elaborar uma predição\n",
    "    Carro_Y_predict = {}\n",
    "    Carro_Y_predict[x] = model_2.predict(Carro_X_test[x])\n",
    "    \n",
    "    ### Calculando as métricas que determinam a qualidade do modelo\n",
    "    r_2 = model_2.score(Separa_dataframe_por_carro(x)[1],Separa_dataframe_por_carro(x)[3])\n",
    "    MSE  = mean_squared_error (Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    MAE  = mean_absolute_error(Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    \n",
    "    ### Função de plotagem com seaborn extraída de:`https://onestopdataanalysis.com/scatter-plot-python/`\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Separa_dataframe_por_carro(x)[3],Carro_Y_predict[x], color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "    \n",
    "    ### Imprimindo as métricas\n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Random Forest Regressor (da Biblioteca SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avisos:\n",
    "    - Apesar do valor default do `random_state` ser `None`, ainda haviam varaiações de resultados quando o modelo era rodado(sem alterar a base de treinamento), isso foi solucionado ao trocar o valor  do `random_state` por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_individual(x):\n",
    "    ### Declarando o modelo como variável global, para que ele possa ser chamado novamente sem perda ou alteração de valor\n",
    "    global model_3\n",
    "    \n",
    "    ### Escolhendo o modelo na biblioteca SciKitLearn\n",
    "    model_3 = RandomForestRegressor(max_depth=12,n_estimators=50,random_state=0)\n",
    "    \n",
    "    ### Fazendo o ajuste do modelo\n",
    "    model_3.fit(Separa_dataframe_por_carro(x)[0],Separa_dataframe_por_carro(x)[2])\n",
    "\n",
    "    ### Usando o modelo ajustado para elaborar uma predição\n",
    "    Carro_Y_predict = {}\n",
    "    Carro_Y_predict[x] = model_3.predict(Carro_X_test[x])\n",
    "    \n",
    "    ### Calculando as métricas que determinam a qualidade do modelo\n",
    "    r_2 = model_3.score(Separa_dataframe_por_carro(x)[1],Separa_dataframe_por_carro(x)[3])\n",
    "    MSE  = mean_squared_error (Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    MAE  = mean_absolute_error(Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    \n",
    "    ### Função de plotagem com seaborn extraída de:`https://onestopdataanalysis.com/scatter-plot-python/`\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Separa_dataframe_por_carro(x)[3],Carro_Y_predict[x], color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "    \n",
    "    ### Imprimindo as métricas\n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<font color=\"#DF1525\">  \n",
    "## Disclaimer:\n",
    "\n",
    "Os trechos de código da seção a seguir foram extraídos de e/ou são fortemente inspirados em:\n",
    "- `https://github.com/VonIgnia/C.Dados-P3/blob/master/Classificador2/_Classificadores.ipynb` \n",
    "</font>  \n",
    "#### Comparação de Modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelos_de_Regressão(tipo, k=False, arvore=False, floresta=False):\n",
    "    # k representa a profundidade da DecisionTree e/ou Random Forest\n",
    "    \n",
    "    ### Escolha do modelo a ser usado na predição\n",
    "    if arvore:\n",
    "        model = tipo(max_depth=k,random_state=0)\n",
    "    elif floresta:\n",
    "        model = tipo(max_depth=k,n_estimators=50,random_state=0)\n",
    "    else:\n",
    "        model = tipo()\n",
    "    \n",
    "    ### Fazendo o ajuste do modelo, independente de qual modelo seja\n",
    "    model.fit(X_train,Y_train)\n",
    "    \n",
    "    ### Usando o modelo ajustado para elaborar uma predição\n",
    "    Y_predict = model.predict(X_test)\n",
    "    \n",
    "    ### Calculando as métricas que determinam a qualidade do modelo\n",
    "    r_2  = model.score(X_test,Y_test)\n",
    "    MSE  = mean_squared_error (Y_test,Y_predict)\n",
    "    MAE  = mean_absolute_error(Y_test,Y_predict)\n",
    "\n",
    "    ### Função de plotagem com seaborn extraída de:`https://onestopdataanalysis.com/scatter-plot-python/`\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Y_test,Y_predict, color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "    \n",
    "    ### Imprimindo as métricas que determinam a qualidade do modelo\n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qualquer coisa para causar erro na rodagem\n",
    "#Como as features a seguir não foram totalmente implementadas, essa célula impede a sua rodagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando um carro, fora do Dataframe e estimando o seu valor (produto para o usuário final)\n",
    "Apesar do conjunto de dados ser bastante extenso, ele não é completo, caso o usuário final deseje consultar o preço de um carro baseado em suas características ele não procuraria por esse carro na base de dados e pelo resultado obtido em um target, e é para isso que a seção a seguir foi criada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def Cria_carro_novo(nome, marca, categoria, loc, ano, km_rodados,modelo):\n",
    "#    info = {'nome':  [nome],\n",
    "#            'marca': [marca],\n",
    "#            'categoria': [categoria],\n",
    "#            'loc': [loc],\n",
    "#            'ano': [ano],\n",
    "#            'km_rodados':[km_rodados]}\n",
    "#    Dataframe = pd.DataFrame (info, columns = ['nome','marca', 'categoria', 'loc', 'ano', 'km_rodados'])\n",
    "#    Dataframe.join(Dummies.drop(columns=['ano','km_rodados']))\n",
    "#    Dataframe = pd.get_dummies(Dataframe.drop(columns=['nome']), prefix=['marca', 'categoria','loc'],dummy_na=False)\n",
    "#    Dataframe.join(pd.get_dummies(Dados['marca']))\n",
    "#    print(Dataframe)\n",
    "#\n",
    "#    result = modelo.predict(Dataframe)# ajustar o número de colunas\n",
    "#    print(result)\n",
    "#    \n",
    "#    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fabricante = list(Dados['marca'].astype('category').values.categories)\n",
    "#tipo = list(Dados['categoria'].astype('category').values.categories)\n",
    "#localização = list(Dados['loc'].astype('category').values.categories)\n",
    "#modelos = {\"Regressão Linear\": model_3,\n",
    "#           \"Árvore de regressões\": model_3,\n",
    "#           \"Random Forest\":model_3} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculadora = interactive(Cria_carro_novo, {'manual': True}, nome=Mais_de_500,\n",
    "#                          marca=fabricante, categoria=tipo,loc=localização,\n",
    "#                          ano=(1982,2020,1), km_rodados=(0,500000,10000),modelo=modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Calculadora)\n",
    "# o erro na previsão se deve a diferença entre o número de colunas\n",
    "# sendo que elas são 50 no treinamento ou fit do modelo e 5 no dataframe criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
