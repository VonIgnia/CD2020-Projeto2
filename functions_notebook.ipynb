{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciência dos Dados 2020 - Projeto 2\n",
    "___\n",
    "- Giovanni Rozatti\n",
    "- Larissa Oliveira da Silva\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#DF2535'>  \n",
    "\n",
    "## Disclaimer:  \n",
    "  \n",
    "A ideia de criar um notebook organizacional foi herdada do P3 feito por Giovanni Rozatti (em conjunto com Daniel G. Terra e Rafael B. Zanfolin) no semestre anterior, o repositório para esse notebook daquele projeto se encontra no link a seguir:`https://github.com/VonIgnia/C.Dados-P3/blob/master/Classificador2/_Fun%C3%A7%C3%B5es.ipynb`\n",
    "- A ideia original pertence a Daniel Terra, e sua execução(no Projeto 3) foi feita em conjunto com Giovanni Rozatti\n",
    "- A maior parte das funções nesse notebook é inédita\n",
    "- Partes diretmente extraídas daquele serão antecedidas por outro disclaimer  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos do Notebook:\n",
    "- O principal propósito desse notebook é a hospedagem e organização das funções que serão utilizados nos outros notebooks desse projeto.  \n",
    "- Outro propósito é uma breve explicação do funcionamento individual de cada uma delas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Imports iniciais\n",
    "- Importa bibliotecas e funções com que trabalharemos ao longo desse notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca para criação de gráficos e visualizações de dados\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca de Machine Learning Open source para python\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Dados\n",
    "- Importa nossa base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados=pd.read_csv('cars_Brazil_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optamos por trabalhar apenas com carros que apareçam no Dataset no mínimo 500 vezes, esse valor foi escolhido de forma a separar o Dataset individual de cada carro em teste e treinamento, com 10% (no mínimo 50 linhas) do Dataset sendo direcionado para teste.   \n",
    "    - <font color=\"#F02510\"> **Observação 04/06: Talvez seja viável reduzir esse limite para 300, em contraponto o limite de 500 já fornece uma base de dados extensa o bastante e informações que parecem ser suficientes para elaborar uma conclusão.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separa carros com mais de 500 ocorrências no Dataframe\n",
    "Mais_de_500 = Dados['nome'].value_counts() > 500\n",
    "Mais_de_500 = list(Mais_de_500.loc[Mais_de_500].index)\n",
    "Dados = Dados.loc[Dados['nome'].isin(Mais_de_500),:];\n",
    "\n",
    "#Converte as variáveis quali em quanti:\n",
    "Dummies = pd.get_dummies(Dados.drop(columns='nome'), prefix=['marca', 'categoria','loc']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando 10% do Dataframe global para treinamento\n",
    "Nota para si mesmo: Estudar se faz sentido ou não eliminar as colunas nome do carro e marca \n",
    "<font color= \"#DD3533\">  \n",
    "    \n",
    "-  (Observação inicial 2 de junho: Não parece fazer)\n",
    "- (Observação secundária 3 de junho: Talvez transformá-los em dummy ou hot-end)\n",
    "   - Tentar Hot-End (Fiz o dummies por praticidade, checar depois. **Anotação 04/06**)\n",
    "   - dummies está pronto (**Anotação 04/06**)\n",
    "- Agora que `dummies` foi criado, analisar quais alterações deverão ser feitas nas funções  \n",
    "(Aparentemente elas seguirão o mesmo formato visto na linha 10 da célula \"Separando 10% do Dataframe de cada carro para treinamento:\")\n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separa características dos carros, que podem ser relevantes no contexto de uma regrssão e \\n\n",
    "# elimina as características irrelevantes assim como a coluna com resultado esperado;\n",
    "inputs = Dummies.drop(columns=[\"valor\"])\n",
    "\n",
    "#separa o resultado esperado, devemos calcular a previsão mais próxima a eles;\n",
    "target = Dummies[\"valor\"]\n",
    "\n",
    "#separando dataframes teste e treino\n",
    "X_train,X_test,Y_train,Y_test=tts(inputs,target,test_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando 10% do Dataframe de cada carro para treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carro         = {}\n",
    "Carro_inputs  = {}\n",
    "Carro_target  = {}\n",
    "Carro_X_train = {}\n",
    "Carro_X_test  = {}\n",
    "Carro_Y_train = {}\n",
    "Carro_Y_test  = {}\n",
    "Carro_Y_predict = {}\n",
    "\n",
    "for x in Mais_de_500:\n",
    "    Carro[x] = Dummies.loc[Dados['nome'] == x]\n",
    "        \n",
    "    Carro_inputs[x] = Carro[x].drop(columns=[\"valor\"])\n",
    "    Carro_target[x] = Carro[x][\"valor\"]\n",
    "        \n",
    "    #separando dataframes teste e treino\n",
    "    Carro_X_train[x],Carro_X_test[x],Carro_Y_train[x],Carro_Y_test[x]=tts(Carro_inputs[x],Carro_target[x],test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar essa informação com a função interact do ipywidgets\n",
    "def Separa_dataframe_por_carro(x):\n",
    "    return (Carro_X_train[x],Carro_X_test[x],Carro_Y_train[x],Carro_Y_test[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Modelos de Regressão e Classificação pré-processados do sklearn:\n",
    "Após observação foi decido na proxima versão alterar o plot, tirando ele do return e internalizando-o na função   \n",
    "<font color=\"#FF2515\">Alterar essa célula aós estar feito para marcar melhoria</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression (da Biblioteca SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_Regression_individual(x):\n",
    "    model = LinearRegression()\n",
    "    model.fit(Separa_dataframe_por_carro(x)[0],Separa_dataframe_por_carro(x)[2])\n",
    "    \n",
    "    Carro_Y_predict = {}\n",
    "    Carro_Y_predict[x] = model.predict(Carro_X_test[x])\n",
    "    \n",
    "    r_2 = model.score(Separa_dataframe_por_carro(x)[1],Separa_dataframe_por_carro(x)[3])\n",
    "    MSE  = mean_squared_error (Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    MAE  = mean_absolute_error(Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    \n",
    "    #Função de plotagem com seaborn extraída de:`https://onestopdataanalysis.com/scatter-plot-python/`\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Separa_dataframe_por_carro(x)[3],Carro_Y_predict[x], color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "    \n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Regression Tree (da Biblioteca SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avisos:\n",
    "    - Apesar do valor default do `random_state` ser `None`, ainda haviam varaiações de resultados quando o modelo era rodado(sem alterar a base de treinamento), isso foi solucionado ao trocar o valor  do `random_state` por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regression_Tree_individual(x):\n",
    "    model = DecisionTreeRegressor(max_depth=12,random_state=0)\n",
    "    model.fit(Separa_dataframe_por_carro(x)[0],Separa_dataframe_por_carro(x)[2])\n",
    "    \n",
    "    Carro_Y_predict = {}\n",
    "    Carro_Y_predict[x] = model.predict(Carro_X_test[x])\n",
    "    \n",
    "    r_2 = model.score(Separa_dataframe_por_carro(x)[1],Separa_dataframe_por_carro(x)[3])\n",
    "    MSE  = mean_squared_error (Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    MAE  = mean_absolute_error(Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    \n",
    "    #Função de plotagem com seaborn extraída de:`https://onestopdataanalysis.com/scatter-plot-python/`\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Separa_dataframe_por_carro(x)[3],Carro_Y_predict[x], color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "    \n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Random Forest Regressor (da Biblioteca SKLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avisos:\n",
    "    - Apesar do valor default do `random_state` ser `None`, ainda haviam varaiações de resultados quando o modelo era rodado(sem alterar a base de treinamento), isso foi solucionado ao trocar o valor  do `random_state` por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_individual(x):\n",
    "    model = RandomForestRegressor(max_depth=12,n_estimators=50,random_state=0)\n",
    "    model.fit(Separa_dataframe_por_carro(x)[0],Separa_dataframe_por_carro(x)[2])\n",
    "    \n",
    "    Carro_Y_predict = {}\n",
    "    Carro_Y_predict[x] = model.predict(Carro_X_test[x])\n",
    "    \n",
    "    r_2 = model.score(Separa_dataframe_por_carro(x)[1],Separa_dataframe_por_carro(x)[3])\n",
    "    MSE  = mean_squared_error (Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    MAE  = mean_absolute_error(Separa_dataframe_por_carro(x)[3], Carro_Y_predict[x])\n",
    "    \n",
    "    #Função de plotagem com seaborn extraída de:`https://onestopdataanalysis.com/scatter-plot-python/`\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Separa_dataframe_por_carro(x)[3],Carro_Y_predict[x], color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "    \n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<font color=\"#FF2515\">  \n",
    "## Disclaimer:\n",
    "\n",
    "Os trechos de código da seção a seguir foram extraídos de e/ou são fortemente inspirados em:\n",
    "- `https://github.com/VonIgnia/C.Dados-P3/blob/master/Classificador2/_Classificadores.ipynb` \n",
    "</font>  \n",
    "#### Comparação de Modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelos_de_Regressão(tipo, k=False, arvore=False, floresta=False):\n",
    "    #k representa a profundidade da DecisionTree e/ou Random Forest\n",
    "    if arvore:\n",
    "        model = tipo(max_depth=k,random_state=0)\n",
    "    elif floresta:\n",
    "        model = tipo(max_depth=k,n_estimators=50,random_state=0)\n",
    "    else:\n",
    "        model = tipo()\n",
    "\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_predict = model.predict(X_test)\n",
    "    \n",
    "    r_2  = model.score(X_test,Y_test)\n",
    "    MSE  = mean_squared_error (Y_test,Y_predict)\n",
    "    MAE  = mean_absolute_error(Y_test,Y_predict)\n",
    "\n",
    "    sn.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(9, 6))\n",
    "    plt.title(\"Comparação Valor real X Previsão\")\n",
    "    scatter = sn.scatterplot(Y_test,Y_predict, color=\"#D02515\")\n",
    "    scatter.set(xlabel=\"Valor Real\", ylabel=\"Previsão\")\n",
    "\n",
    "    print (\"R-squared: {0:.4f}\".format(r_2))\n",
    "    print (\"Mean Squared Error: {0:.2f}\" .format(MSE))\n",
    "    print (\"Mean Absolute Error: {0:.2f}\".format(MAE))\n",
    "    \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
