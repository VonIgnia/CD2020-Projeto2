{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciência dos Dados 2020 - Projeto 2\n",
    "___\n",
    "- Giovanni Rozatti\n",
    "- Larissa Oliveira da Silva\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#DF2535'>  \n",
    "## Disclaimer$^{_1}$:  \n",
    "  \n",
    "A ideia de criar um notebook organizacional foi herdada do P3 feito por Giovanni Rozatti (em conjunto com Daniel G. Terra e Rafael B. Zanfolin) no semestre anterior, o repositório para esse notebook daquele projeto se encontra no link a seguir:`https://github.com/VonIgnia/C.Dados-P3/blob/master/Classificador2/_Fun%C3%A7%C3%B5es.ipynb`\n",
    "- A ideia original pertence a Daniel Terra, e sua execução(no Projeto 3) foi feita em conjunto com Giovanni Rozatti\n",
    "- A maior parte das funções nesse notebook é inédita\n",
    "- Partes diretmente extraídas daquele serão marcadas por outro disclaimer  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos do Notebook:\n",
    "- O principal propósito desse notebook é a hospedagem e organização das funções que serão utilizados nos outros notebooks desse projeto.  \n",
    "- Outro propósito é uma breve explicação do funcionamento individual de cada uma delas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Imports iniciais\n",
    "- Importa bibliotecas e funções com que trabalharemos ao longo desse notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Dados\n",
    "- Importa nossa base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados=pd.read_csv('cars_Brazil_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optamos por trabalhar apenas com carros que apareçam no Dataset no mínimo 500 vezes, esse valor foi escolhido de forma a separar o Dataset individual de cada carro em teste e treinamento, com 10% (no mínimo 50 linhas) do Dataset sendo direcionado para teste. -Observação 04/06: Talvez seja viável reduzir esse limite para 300, em contraponto o limite de 500 já fornece uma base de dados extensa o bastante e informações que parecem ser suficientes para elaborar uma conclusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separa carros com mais de 500 ocorrências no Dataframe\n",
    "Mais_de_500 = Dados['nome'].value_counts() > 500\n",
    "Mais_de_500 = list(Mais_de_500.loc[Mais_de_500].index)\n",
    "Dados = Dados.loc[Dados['nome'].isin(Mais_de_500),:];\n",
    "\n",
    "#Converte as variáveis quali em quanti:\n",
    "Dummies = pd.get_dummies(Dados.drop(columns='nome'), prefix=['marca', 'categoria','loc']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando 10% do Dataframe global para treinamento\n",
    "Nota para si mesmo: Estudar se faz sentido ou não eliminar as colunas nome do carro e marca \n",
    "<font color= \"#DD3533\">  \n",
    "    \n",
    "-  (Observação inicial 2 de junho: Não parece fazer)\n",
    "- (Observação secundária 3 de junho: Talvez transformá-los em dummy ou hot-end)\n",
    "   - Tentar Hot-End (Fiz o dummies por praticidade, checar depois Anotação 04/06)\n",
    "   - dummies está pronto\n",
    "- Agora que `dummies` foi criado, analisar quais alterações deverão ser feitas nas funções  \n",
    "(Aparentemente elas seguirão o mesmo formato visto na linha 10 da célula \"Separando 10% do Dataframe de cada carro para treinamento:\")\n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separa características dos carros, que podem ser relevantes no contexto de uma regrssão e \\n\n",
    "# elimina as características irrelevantes assim como a coluna com resultado esperado;\n",
    "inputs = Dummies.drop(columns=[\"valor\"])\n",
    "\n",
    "#separa o resultado esperado, devemos calcular a previsão mais próxima a eles;\n",
    "target = Dummies[\"valor\"]\n",
    "\n",
    "#separando dataframes teste e treino\n",
    "X_train,X_test,Y_train,Y_test=tts(inputs,target,test_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando 10% do Dataframe de cada carro para treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Carro         = {}\n",
    "Carro_inputs  = {}\n",
    "Carro_target  = {}\n",
    "Carro_X_train = {}\n",
    "Carro_X_test  = {}\n",
    "Carro_Y_train = {}\n",
    "Carro_Y_test  = {}\n",
    "\n",
    "for x in Mais_de_500:\n",
    "    Carro[x] = Dummies.loc[Dados['nome'] == x]\n",
    "        \n",
    "    Carro_inputs[x] = Carro[x].drop(columns=[\"valor\"])\n",
    "    Carro_target[x] = Carro[x][\"valor\"]\n",
    "        \n",
    "    #separando dataframes teste e treino\n",
    "    Carro_X_train[x],Carro_X_test[x],Carro_Y_train[x],Carro_Y_test[x]=tts(Carro_inputs[x],Carro_target[x],test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar essa informação com a função interact do ipywidgets\n",
    "def Separa_dataframe_por_carro(x):\n",
    "    return (Carro_X_train[x],Carro_X_test[x],Carro_Y_train[x],Carro_Y_test[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Funções de Filtragem e Separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar essa informação com a função interact do ipywidgets\n",
    "def Separa_por_veículo(x):\n",
    "    return Dummies.loc[Dados['nome'] == x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interact (Separa_por_veículo, x=Mais_de_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar essa informação com a função interact do ipywidgets\n",
    "#alterar as dimensões do scatter plot (quase que certamente valor não depende exclusivamente dos km_rodados)\n",
    "def Dispersão_individual_por_veículo(x):\n",
    "    gráfico_de_dispersão  = plt.scatter (Dummies.loc[Dados['nome'] == x]['valor'],Dummies.loc[Dados['nome'] == x]['km_rodados'])\n",
    "    return gráfico_de_dispersão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interact (Dispersão_individual_por_veículo, x=Mais_de_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.cm.get_cmap('Spectral')\n",
    "\n",
    "def Dispersão_global_por_veículo(lista):\n",
    "    t=0\n",
    "    for x in lista:\n",
    "        plt.scatter (Dummies.loc[Dados['nome'] == x]['valor'],Dummies.loc[Dados['nome'] == x]['km_rodados'],\n",
    "                 label=x, c=[cmap(t * 1/(len(lista)-1))]) \n",
    "        t+=1\n",
    "        #Acrescentar um sistema de arange de cores (colormap?)\n",
    "        plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dispersão_global_por_veículo(Mais_de_500);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Modelos de Regressão e Classificação pré-processados do sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(max_depth=10,n_estimators=10)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(np.arange(0,200000),np.arange(0,200000), color='red')\n",
    "#plt.scatter(Y_test,Y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
